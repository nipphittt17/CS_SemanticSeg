{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"device: {DEVICE}\")"
      ],
      "metadata": {
        "id": "GOheNF1ej8IC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4a345bc-f7fd-4a5f-c13c-e53a04962279"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and import required libraries"
      ],
      "metadata": {
        "id": "8D13dQxc-j-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install timm"
      ],
      "metadata": {
        "id": "9QZp12rRx--K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beae28b0-7b47-4fcf-eb75-02dcaec8356a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.9/dist-packages (0.6.13)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from timm) (0.15.1+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/dist-packages (from timm) (0.13.4)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.9/dist-packages (from timm) (2.0.0+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from timm) (5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (3.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.7->timm) (2.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "\n",
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "id": "myUfnB9dz5yu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4887f18f-b166-4b92-df20-b95e16779b1c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.9/dist-packages (5.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.9/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python) (0.18.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import cv2\n",
        "import ffmpeg\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "2XPZRDGSibRs"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount to google drive and specify path"
      ],
      "metadata": {
        "id": "fk66Y8rv-xEy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "fhabNwvxWldO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1188983-c496-4794-9f46-b053aecc92c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder_path = \"/content/drive/MyDrive/Colab Notebooks/data/Project\" #change your path here"
      ],
      "metadata": {
        "id": "3PIrU8DHf45S"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Unet architecture and load the model"
      ],
      "metadata": {
        "id": "xw-G1zCi--DO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "    \n",
        "class Down(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.mpconv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.mpconv(x)\n",
        "    \n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels//2, in_channels//2, kernel_size=2, stride=2)\n",
        "        \n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "    \n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels=4, n_classes=3, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "        \n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 512)\n",
        "        self.up1 = Up(1024, 256, bilinear)\n",
        "        self.up2 = Up(512, 128, bilinear)\n",
        "        self.up3 = Up(256, 64, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "2g96xapbjHfz"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet(4,3)\n",
        "model = model.to(DEVICE)"
      ],
      "metadata": {
        "id": "mJNBOS0kjznS"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(input_folder_path+\"/my_checkpoint.pth.tar\")[\"state_dict\"])"
      ],
      "metadata": {
        "id": "4rD5U_-pipgj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3eb013f-39f0-4784-969f-44844c254a38"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the target video"
      ],
      "metadata": {
        "id": "Hoi7TSn-_D5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.isfile(input_folder_path+\"/vdo_3.mp4\"): #change the video name here\n",
        "    print('found')"
      ],
      "metadata": {
        "id": "CAZS8RfAj-Vl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aba1614-23ce-42c1-923d-1c9ed01ade3c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vidcap = cv2.VideoCapture(os.path.join(input_folder_path+\"/vdo_3.mp4\")) #change the video name here\n",
        "frame_count = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "target_img_w = 720\n",
        "target_img_h = 480"
      ],
      "metadata": {
        "id": "4pwcSKpUkk8u"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import midas to create depth map"
      ],
      "metadata": {
        "id": "kyymYmXH_PyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "midas = torch.hub.load(\"intel-isl/MiDaS\", \"DPT_Large\")\n",
        "midas.to(DEVICE)\n",
        "midas.eval()\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "transform = midas_transforms.dpt_transform"
      ],
      "metadata": {
        "id": "telhDnNAkszA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65884935-b4f2-4af2-bc2b-f401972efef3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n",
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_depth_map(img, midas, transform, device):\n",
        "    # Process the image with the MiDaS model\n",
        "    input_batch = transform(img).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = midas(input_batch)\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "            prediction.unsqueeze(1),\n",
        "            size=img.shape[:2],\n",
        "            mode=\"nearest-exact\",\n",
        "        ).squeeze()\n",
        "    depth_map = prediction.cpu().numpy()\n",
        "\n",
        "    return depth_map"
      ],
      "metadata": {
        "id": "1UIKLVVcx6hz"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the video output "
      ],
      "metadata": {
        "id": "a_iDpd9E_Vhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Output Stream\n",
        "out_stream = (\n",
        "    ffmpeg\n",
        "    .input('pipe:', format='rawvideo', pix_fmt='rgb24', s='{}x{}'.format(target_img_w, target_img_h))\n",
        "    .output('output3.mp4', pix_fmt='rgb24')\n",
        "    .overwrite_output()\n",
        "    .run_async(pipe_stdin=True)\n",
        ")\n",
        "\n",
        "success, image = vidcap.read()\n",
        "with tqdm(total=frame_count, position=0, leave=True) as pbar:\n",
        "    predictions = []\n",
        "    while success:\n",
        "        image = cv2.resize(\n",
        "            image, (target_img_w, target_img_h), \n",
        "            interpolation=cv2.INTER_LINEAR)\n",
        "        \n",
        "        # Generate the depth map using the MiDaS model\n",
        "        depth_map = get_depth_map(image, midas, transform, DEVICE)\n",
        "        \n",
        "        # Convert the image and depth map to a PyTorch tensor and normalize them\n",
        "        image_tensor = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0) / 255.0\n",
        "        depth_map_tensor = torch.tensor(depth_map, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "        image_tensor = torch.cat([image_tensor, depth_map_tensor], dim=1)\n",
        "        image_tensor = image_tensor.to(DEVICE)\n",
        "\n",
        "        # Uss U-Net model for segmentation\n",
        "        logits = model(image_tensor)\n",
        "        pred_masks = torch.argmax(logits, dim=1).squeeze(0).cpu().numpy()\n",
        "        \n",
        "        # Visualize the segmentation results\n",
        "        out_image = np.zeros_like(image)\n",
        "        for i in range(0, 3):  \n",
        "            masks = pred_masks == i\n",
        "            if i == 0:\n",
        "                color = [61, 11, 81]  \n",
        "            elif i == 1:\n",
        "                color = [69, 142, 139] \n",
        "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "                text = \"Detected\"\n",
        "                position = (50, 50)\n",
        "                font_scale = 1\n",
        "                font_color = (255, 255, 255)\n",
        "                line_type = 2\n",
        "                cv2.putText(out_image, text, position, font, font_scale, font_color, line_type) \n",
        "            else:\n",
        "                color = [250, 230, 85] \n",
        "\n",
        "            out_image[masks] = color  # Set the color for the current class\n",
        "        \n",
        "        out_stream.stdin.write(\n",
        "            out_image\n",
        "            .astype(np.uint8)\n",
        "            .tobytes()\n",
        "        )\n",
        "        pbar.update()\n",
        "        success, image = vidcap.read()\n",
        "        predictions.append(pred_masks)\n",
        "\n",
        "out_stream.stdin.close()\n"
      ],
      "metadata": {
        "id": "DyCkPAFtznDl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc9ca0f0-2ff5-4b99-d909-c49296f7d324"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 455/455 [02:58<00:00,  2.55it/s]\n"
          ]
        }
      ]
    }
  ]
}